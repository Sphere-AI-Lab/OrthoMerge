bash /data/yangsihan/lm-evaluation-harness/mergebench_eval_all.sh /home/yangsihan/models/MergeBench_merged/Llama-3.1-8B_decouple_ta_procrustes_cosine_similarity_target_then_decouple_ta_TIES_try_recover_best_result_orthoAndTIES_layerwise-compute-conflict-procrustes-multiGPU_layerwise-calDelta-beforeTIES 0 /data/yangsihan/lm-evaluation-harness/results/Llama-3.1-8B_decouple_ta_procrustes_cosine_similarity_target_then_decouple_ta_TIES_try_recover_best_result_orthoAndTIES_layerwise-compute-conflict-procrustes-multiGPU_layerwise-calDelta-beforeTIES

bash /data/yangsihan/lm-evaluation-harness/eval_oft_exp_forgetting.sh /home/yangsihan/models/Llama-3.1-8B_merged/TSVM_lora_commonsenseqa_magicoder1e-4_fastmath_socialiqa_scienceqa_search_hyperparameter/hp1.0 3 /data/yangsihan/lm-evaluation-harness/oft_model_forgetting_results/Llama-3.1-8B_merged/TSVM_lora_commonsenseqa_magicoder1e-4_fastmath_socialiqa_scienceqa_search_hyperparameter/hp1.0


bash /data/yangsihan/lm-evaluation-harness/eval_oft_exp_general.sh /home/yangsihan/models/Llama-3.1-8B_merged/OM_avg_Q_commonsenseqa_magicoder_socialiqa_scienceqa_numinamath/merged_model 0 /data/yangsihan/lm-evaluation-harness/oft_model_forgetting_results/Llama-3.1-8B_merged/OM_avg_Q_commonsenseqa_magicoder_socialiqa_scienceqa_numinamath
bash /data/yangsihan/lm-evaluation-harness/eval_oft_exp_general.sh /home/yangsihan/models/Llama-3.1-8B_merged/TA_oft_commonsenseqa_magicoder_numinamath_socialiqa_scienceqa_search_hyperparameter/hp_0.2 0 /data/yangsihan/lm-evaluation-harness/oft_model_forgetting_results/Llama-3.1-8B_merged/TA_oft_commonsenseqa_magicoder_numinamath_socialiqa_scienceqa_search_hyperparameter/hp_0.2
bash /data/yangsihan/lm-evaluation-harness/eval_oft_exp_general.sh /home/yangsihan/models/Llama-3.1-8B_merged/DARE_oft_commonsenseqa_magicoder_numinamath_socialiqa_scienceqa_search_hyperparameter/sparsity0.7_rescaleTrue 1 /data/yangsihan/lm-evaluation-harness/oft_model_forgetting_results/Llama-3.1-8B_merged/DARE_oft_commonsenseqa_magicoder_numinamath_socialiqa_scienceqa_search_hyperparameter/sparsity0.7_rescaleTrue
bash /data/yangsihan/lm-evaluation-harness/eval_oft_exp_general.sh /home/yangsihan/models/Llama-3.1-8B 1 /data/yangsihan/lm-evaluation-harness/oft_model_forgetting_results/Llama-3.1-8B
bash /data/yangsihan/lm-evaluation-harness/eval_oft_exp_general.sh /home/yangsihan/models/Llama-3.1-8B_merged/TSVM-fusion-bench_oft_commonsenseqa_magicoder_numinamath_socialiqa_scienceqa_search_hyperparameter/hp1.0 2 /data/yangsihan/lm-evaluation-harness/oft_model_forgetting_results/Llama-3.1-8B_merged/TSVM-fusion-bench_oft_commonsenseqa_magicoder_numinamath_socialiqa_scienceqa_search_hyperparameter/hp1.0


bash /data/yangsihan/lm-evaluation-harness/eval_oft_exp_general.sh /home/yangsihan/models/Llama-3.1-8B_merged/TIES_lora_commonsenseqa_magicoder1e-4_fastmath_socialiqa_scienceqa_search_hyperparameter/hp_0.2_1.0 2 /data/yangsihan/lm-evaluation-harness/oft_model_forgetting_results/Llama-3.1-8B_merged/TIES_lora_commonsenseqa_magicoder1e-4_fastmath_socialiqa_scienceqa_search_hyperparameter/hp_0.2_1.0
bash /data/yangsihan/lm-evaluation-harness/eval_oft_exp_general.sh /home/yangsihan/models/Llama-3.1-8B_merged/TSVM_lora_commonsenseqa_magicoder1e-4_fastmath_socialiqa_scienceqa_search_hyperparameter/hp1.0 3 /data/yangsihan/lm-evaluation-harness/oft_model_forgetting_results/Llama-3.1-8B_merged/TSVM_lora_commonsenseqa_magicoder1e-4_fastmath_socialiqa_scienceqa_search_hyperparameter/hp1.0
bash /data/yangsihan/lm-evaluation-harness/eval_oft_exp_general.sh /home/yangsihan/models/Llama-3.1-8B_merged/DARE_lora_commonsenseqa_magicoder1e-4_fastmath_socialiqa_scienceqa_search_hyperparameter/sparsity0.7_rescaleTrue 3 /data/yangsihan/lm-evaluation-harness/oft_model_forgetting_results/Llama-3.1-8B_merged/DARE_lora_commonsenseqa_magicoder1e-4_fastmath_socialiqa_scienceqa_search_hyperparameter/sparsity0.7_rescaleTrue
bash /data/yangsihan/lm-evaluation-harness/eval_oft_exp_general.sh /home/yangsihan/models/Llama-3.1-8B_merged/TA_lora_commonsenseqa_magicoder1e-4_fastmath_socialiqa_scienceqa_search_hyperparameter/hp_0.2 4 /data/yangsihan/lm-evaluation-harness/oft_model_forgetting_results/Llama-3.1-8B_merged/TA_lora_commonsenseqa_magicoder1e-4_fastmath_socialiqa_scienceqa_search_hyperparameter/hp_0.2

/home/yangsihan/models/Llama-3.1-8B_merged/OM_avg_Q_Ax_theta-mean_commonsenseqa_magicoder_socialiqa_scienceqa_numinamath/merged_model
/home/yangsihan/models/Llama-3.1-8B_merged/OM_avg_Q_commonsenseqa_magicoder_socialiqa_scienceqa_numinamath/merged_model

/home/yangsihan/models/Llama-3.1-8B_merged/oft_5experts_TIES
/home/yangsihan/models/Llama-3.1-8B_merged/TSVM-fusion-bench_oft_commonsenseqa_magicoder_numinamath_socialiqa_scienceqa_search_hyperparameter/hp1.0
/home/yangsihan/models/Llama-3.1-8B_merged/DARE_oft_commonsenseqa_magicoder_numinamath_socialiqa_scienceqa_search_hyperparameter/sparsity0.7_rescaleTrue
/home/yangsihan/models/Llama-3.1-8B_merged/TA_oft_commonsenseqa_magicoder_numinamath_socialiqa_scienceqa_search_hyperparameter/hp_0.2









cd /data/yangsihan/OrthogonalModelMerging/OFT_LLM
conda activate oft_llm
CUDA_VISIBLE_DEVICES=6 python /data/yangsihan/OrthogonalModelMerging/OFT_LLM/eval_scienceqa.py --merged_dir /home/yangsihan/models/Llama-3.1-8B_merged/OM_avg_Q_commonsenseqa_magicoder_socialiqa_scienceqa_numinamath/merged_model
conda activate lm-eval; cd /data/yangsihan/lm-evaluation-harness
export HF_ALLOW_CODE_EVAL=1
CUDA_VISIBLE_DEVICES=6 lm_eval --model hf \
    --tasks minerva_math500,social_iqa,commonsense_qa \
    --model_args pretrained=/home/yangsihan/models/Llama-3.1-8B_merged/OM_avg_Q_commonsenseqa_magicoder_socialiqa_scienceqa_numinamath/merged_model \
    --device cuda:0 \
    --batch_size 1 \
    --confirm_run_unsafe_code
conda activate bigcode; cd /data/yangsihan/bigcode-evaluation-harness
export CUDA_VISIBLE_DEVICES=6
accelerate launch  main.py \
  --model /home/yangsihan/models/Llama-3.1-8B_merged/OM_avg_Q_commonsenseqa_magicoder_socialiqa_scienceqa_numinamath/merged_model \
  --max_length_generation 2048 \
  --precision bf16 \
  --tasks humanevalplus \
  --temperature 0.2 \
  --n_samples 10 \
  --batch_size 10 \
  --allow_code_execution \
  --use_auth_token



/home/yangsihan/models/Llama-3.2-3B_finetuned/merged/magicoder_lora_merged_model_epoch2_lr2e-4_bs64_r32_alpha64_dropout0-05
/home/yangsihan/models/Llama-3.2-3B_finetuned/merged/NuminaMath_lora_merged_model_epoch2_lr2e-4_bs64_r32_alpha64_dropout0-05
/home/yangsihan/models/Llama-3.2-3B_finetuned/csqa_lora_merged_model_epoch2_lr2e-4_bs64_r32_alpha64_dropout0-05
/home/yangsihan/models/Llama-3.2-3B_finetuned/socialiqa_lora_merged_model_epoch2_lr2e-4_bs64_r32_alpha64_dropout0-05
/home/yangsihan/models/Llama-3.2-3B_finetuned/scienceqa_lora_merged_model_epoch2_lr2e-4_bs64_r32_alpha64_dropout0-05

/home/yangsihan/models/Llama-3.2-3B_finetuned/magicoder_merged_model_epoch2_lr2e-4_bs64_dropout0-05
/home/yangsihan/models/Llama-3.2-3B_finetuned/merged/NuminaMath_merged_model_epoch2_lr2e-4_bs64_dropout0-05
/home/yangsihan/models/Llama-3.2-3B_finetuned/csqa_merged_model_epoch1_lr2e-4_bs64_dropout0-05
/home/yangsihan/models/Llama-3.2-3B_finetuned/socialiqa_merged_model_epoch2_lr2e-4_bs64_dropout0-05
/home/yangsihan/models/Llama-3.2-3B_finetuned/scienceqa_merged_model_epoch1_lr2e-4_bs64_dropout0-05


cd /data/yangsihan/OrthogonalModelMerging/OFT_LLM
conda activate oft_llm
CUDA_VISIBLE_DEVICES=4 python /data/yangsihan/OrthogonalModelMerging/OFT_LLM/eval_scienceqa.py --merged_dir /home/yangsihan/models/llama3-1_8b_finetune_scienceqa/oft-finetune_merged_model_oftBS32_lr2p0e-04_ep2_bs64_drop0.05
    --device cuda:0 \
conda activate lm-eval; cd /data/yangsihan/lm-evaluation-harness
CUDA_VISIBLE_DEVICES=4 lm_eval --model hf \
    --tasks social_iqa \
    --model_args pretrained=/home/yangsihan/models/llama3-1_8b_finetune_socialiqa/oft-finetune_merged_model_oftBS32_lr2p0e-04_ep2_bs64_drop0.05 \
    --device cuda:0 \
    --batch_size 1 \
    --confirm_run_unsafe_code
conda activate lm-eval; cd /data/yangsihan/lm-evaluation-harness
CUDA_VISIBLE_DEVICES=4 lm_eval --model hf \
    --tasks commonsense_qa \
    --model_args pretrained=/home/yangsihan/models/llama3-1_8b_finetune_commonsense/oft-finetune_merged_model_oftBS32_lr2p0e-04_ep2_bs64_drop0.05 \
    --batch_size 1 \
    --confirm_run_unsafe_code

conda activate lm-eval; cd /data/yangsihan/lm-evaluation-harness
export HF_ALLOW_CODE_EVAL=1
CUDA_VISIBLE_DEVICES=5 lm_eval --model hf \
    --tasks mbpp \
    --model_args pretrained=/home/yangsihan/models/llama3-1_8b_finetune_magicoder/oft-finetune_merged_model_oftBS32_lr2p0e-04_ep2_bs64_drop0.05 \
    --device cuda:0 \
    --batch_size 1 \
    --confirm_run_unsafe_code


conda activate bigcode; cd /data/yangsihan/bigcode-evaluation-harness
export CUDA_VISIBLE_DEVICES=4
accelerate launch  main.py \
  --model /home/yangsihan/models/Llama-3.1-8B_merged/OM_avg_Q_Ax_theta-mean_commonsenseqa_magicoder_socialiqa_scienceqa_numinamath/merged_model \
  --max_length_generation 2048 \
  --precision bf16 \
  --tasks humaneval \
  --temperature 0.2 \
  --n_samples 10 \
  --batch_size 10 \
  --allow_code_execution \
  --use_auth_token

conda activate lm-eval; cd /data/yangsihan/lm-evaluation-harness
CUDA_VISIBLE_DEVICES=0 lm_eval --model hf \
    --tasks minerva_math500 \
    --model_args pretrained=/home/yangsihan/models/Llama-3.1-8B_merged/OM_avg_Q_Ax_theta-mean_commonsenseqa_magicoder_socialiqa_scienceqa_numinamath/merged_model \
    --device cuda:0 \
    --batch_size 1 \
    --confirm_run_unsafe_code

conda activate lm-eval; cd /data/yangsihan/lm-evaluation-harness
CUDA_VISIBLE_DEVICES=3 lm_eval --model hf \
    --tasks gsm8k_cot \
    --model_args pretrained=/home/yangsihan/models/llama3-1_8b_finetune_numinamath/oft-finetune_merged_model_oftBS32_lr2p0e-04_ep2_bs64_drop0.05 \
    --device cuda:0 \
    --batch_size 1 \
    --confirm_run_unsafe_code


